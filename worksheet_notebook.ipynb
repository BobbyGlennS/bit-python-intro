{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Python - Worksheet\n",
    "\n",
    "## Section 0: Setting up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is great.\n",
    "But it's a little bare bones.\n",
    "We need to import some libraries if we want to do data science.\n",
    "\n",
    "Libraries?\n",
    "Consider Python as your workbench.\n",
    "Libraries are like little lovingly crafted bags (independent shop vibes) with specific tools that allow you to create beautiful things on your workbench. \n",
    "Typically, you need to install libraries on your machine, but as we're using colab, they come pre-installed.\n",
    "We will cover installation of libraries in a separate session. \n",
    "R users will recognise the concept of libraries but might think of them as 'packages'.\n",
    "\n",
    "A very commonly used library in data science is [pandas](https://pandas.pydata.org/). \n",
    "It provides easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "We will use it a lot in this workshop.\n",
    "\n",
    "Other libraries often used are:\n",
    "\n",
    "- numpy: helps with doing maths on colletions of numbers (like a matrix).\n",
    "- sci-kitlearn & statsmodels fit machine learning and statistical models.\n",
    "- matplotlib, seaborn, and plotly are libraries used for data viz.\n",
    "\n",
    "For this workshop we will at least need pandas and a specific module that comes with plotly, named graph_objects. \n",
    "We import them in the following cell.\n",
    "\n",
    "Put your cursor in the cell and pressing `ctrl+enter` will execute the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: moving forward we will call a lot of the tools (called methods and functions) that come with pandas. \n",
    "Because we don't want to type 'pandas' everytime, we say 'as pd'. \n",
    "It means that we can now refer to pandas as pd, which saves a bit of typing. \n",
    "It is not essential.\n",
    "You can see we've done the same for plotly.graph_objects.\n",
    "\n",
    "As a next step, we will import the data we'll be playing around with today.\n",
    "Again, put your cursor in the cell, and press `ctrl+enter`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/BobbyGlennS/bit-python-intro/main/data/combined_matches.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dissect this piece of code a little bit:\n",
    "\n",
    "`df`    \n",
    "We don't just want to load the data, we will also need to tell python to store it somewhere. We are creating a variable named `df`. It will serve as a pointer to the data that we are about to load into the memory. This way python knows to keep hold of it, and let us bring it back up everytime we type `df`.\n",
    "\n",
    "\n",
    "`=`  \n",
    "We're telling python that this new variable should point to the result of the code that follows the equals sign (`=`).  \n",
    "\n",
    "`pd.read_csv`  \n",
    "Use the function read_csv from the pandas library (which we said we would refer to as pd).  \n",
    "\n",
    "`('https://....')`  \n",
    "Between the parentheses we provide an 'argument'. It's an instruction to the function. In this case the instruction is: 'go here to retrieve the file'.\n",
    "\n",
    "Great! \n",
    "If all went well we now have a dataset loaded.\n",
    "It's stored in Python's memory in an object called a pandas DataFrame, which we can retrieve by typing `df`.\n",
    "\n",
    "We can start playing.\n",
    "Let's first have a little look.\n",
    "Let's print the dataframe with a function named `print()`.\n",
    "\n",
    "Like with `read_csv()`, we write the function and between the parentheses we provide an argument that contains an instruction for the function to work with. In this case the instruction is to print of whatever we provide as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use also the *method* head() on a pandas DataFrame to get the first few rows, which looks slightly nicer.\n",
    "\n",
    "The technical distinction between methods and functions is something for another time. But what is useful to know is that methods are like little appendices that come with certain objects. A pandas DataFrame has a set of methods that you can use on it. For example to explore the dataframe, which is what we will be doing in the next few code cells.\n",
    "\n",
    "We call them slightly differently than functions: we write the object we want to use a method with, and then after the dot we write the name of the method.\n",
    "See below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also give methods specific instructions. That's what the parentheses are for! E.g. you can ask for a specific number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaving methods behind now for a second.\n",
    "\n",
    "We can also ask pandas to display specific columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# view tourney date, tourney name, and winner name columns\n",
    "df[['tourney_date', 'tourney_name', 'winner_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can combine different operations.\n",
    "We call this 'chaining'.\n",
    "This code is executed sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df[['tourney_date', 'tourney_name', 'winner_name']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some other operations that you may find useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#get column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# how many rows and columns?\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 0.1\n",
    "\n",
    "You've now seen a few ways to explore a dataframe.\n",
    "\n",
    "In the next cell, have a go yourself.\n",
    "\n",
    "- Can you create a subset of data by *sampling* 20 rows from a select set of *colums* of your choice? *Note: don't just select the top 5 rows, but sample some at random.*\n",
    "- Can you store this subset in a new pandas DataFrame, named `df2`?\n",
    "- Can you check the dimensions of this new dataframe?\n",
    "\n",
    "For this, you will need to use at least one new method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Diving in\n",
    "\n",
    "Now we are setup, we will ask you to do some exercises to answer two questions:\n",
    "\n",
    "- Who won the most Grand Slam Tournaments between 2000 and 2019? \n",
    "- Who won the most Australian Opens in the same period? \n",
    "\n",
    "For this, we will have to transform some of the data from one form into another. \n",
    "We call this process *Data Wrangling*.\n",
    "\n",
    "Let's have a go.\n",
    "\n",
    "Useful functions: \\\n",
    "\\\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html \\\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html \\\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html \\\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html\n",
    "\n",
    "Read about using plotly here: \\\n",
    "\\\n",
    "https://plotly.com/python-api-reference/generated/plotly.graph_objects.Bar.html\n",
    "\n",
    "### Exercise 1.1: Sort out the match dates\n",
    "\n",
    "So that we can select tournaments from the right time period, we need to make sure the date of the matches is in the right format.\n",
    "\n",
    "Find the column that stores the match dates and reformat it so that it is a date, stored as YYYY-MM-DD.\n",
    "\n",
    "For this exercise, consider using the [datetime](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html) method. \n",
    "You can also start with a google or a GPT question on how to turn a pandas column into the format YYYY-MM-DD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Identify finals matches from Grand Slam Tournaments\n",
    "\n",
    "We only want to include final matches from grand slam tournaments in the dataframe, as they will tell us who won the relevant tournaments.\n",
    "For this we need to work out where we get that information from.\n",
    "\n",
    "- First work out which column will tell us what round a match was part of, and how you might identify final rounds.\n",
    "- Then do the same for tournaments, find the column that tells us the level of a tournament, and how we can identify grand slam tournaments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During your exploration, you may have noticed that that Australian Open and US Open tournaments are recorded in a variety of ways in the dataset.\n",
    "Inconsistencies in data is something that often happens!\n",
    "Below is included a code cell that takes care of this.\n",
    "Henry or Bobby can explain to you how this works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {},
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Setting up a dictionary of desired replacements\n",
    "replacements = {\n",
    "    'Us Open' : 'US Open',\n",
    "    'Australian Open-2' : 'Australian Open',\n",
    "    'Australian Chps.' : 'Australian Open',\n",
    "    'Australian Open 2' : 'Australian Open',\n",
    "    'Australian Championships' : 'Australian Open'\n",
    "}\n",
    "\n",
    "# Doing the replacements\n",
    "df['tourney_name'] = df['tourney_name'].replace(replacements)\n",
    "\n",
    "# Checking the replacements\n",
    "df[df['tourney_level'] == 'G']['tourney_name'].value_counts()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! This has worked and we are ready to make our filtered dataframe.\n",
    "\n",
    "### Exercise 1.4: Filter the data \n",
    "\n",
    "Next we want to create a dataset that only contains the data we are interested in. \n",
    "This is known as filtering.\n",
    "\n",
    "As a reminder the data should only contain:\n",
    "- Data from grand slam tournaments\n",
    "- The final rounds of those tournaments\n",
    "- Only between 2000 and 2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.5 Find who won the most grand slam tournaments between 2000 and 2019. Plot a bar chart with this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.6: Make a bar chart showing which 5 players won the most Australian Opens between 2000 and 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution is very similar. Note that we have to add the condition that the tournament name is `Australian Open`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.7 How young were the top winners when they won a grand slam for the first time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: BONUS: Analysing Streaks\n",
    "\n",
    "Through this section, we will be analysing grand slam winning streaks from the men's dataframe.\n",
    "\n",
    "Usefull functions: \n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html \\\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eq.html \\\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumsum.html \\\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.Index.get_level_values.html\n",
    "\n",
    "## Question 1: Which Male Players had the Longest Grand Slam Winning Streaks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Filter the grand slams dataframe to only include male players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataframe into male and female players\n",
    "gs_df_men = gs_df[gs_df['Tour'] == 'ATP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Shift the 'winner_name' column in the men's dataframe down by one using the shift function.\n",
    "\n",
    "Let's see what the shift function does to a column. First we check what the column looks like before applying the shift function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the 'winner_name' column before applying the shift function\n",
    "gs_df_men['winner_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shifting the 'winner_name' column down by 1\n",
    "gs_df_men['winner_name'].shift()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to shist the whole column down by one. Notice that the index remains the same. This is important for comparing the shifted row to the original. \n",
    "\n",
    "Now let's see what the eq function does. \n",
    "\n",
    "### Exercise 3.2: Use the `eq` function to compare the shifted 'winner_name' to the original. What is the result? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_df_men['winner_name'].eq(gs_df_men['winner_name'].shift())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a boolean array indicating when the two columns are the same (True), and when they are not (False).\n",
    "\n",
    "### Exercise 3.3: How can we use these functions to determine grand slam winning streaks for each player?\n",
    "\n",
    "Hint: you might find it helpful to use the `cumsum` function, with which you can sum values in a boolean array (https://pandas.pydata.org/docs/dev/reference/api/pandas.DataFrame.cumsum.html). \n",
    "\n",
    "Hint: also see https://joshdevlin.com/blog/calculate-streaks-in-pandas/#:~:text=The%20first%20step%20in%20calculating,us%20which%20are%20not%20equal for a blog post on how to find streaks in a dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution:\n",
    "\n",
    "We will solve this problem by first adding a `streak_indicator` column, that will be a boolean (as above) that indicates when the winning player is the same as in the shifted `winner_name` column. Then we will negate this column so that `False` indicates that the `winner_name` is the same as the previous `winner_name`. We can now apply the `cumsxum` function and create a new streak indicator column whose entries will be numbers that increment by 1 everytime a new streak is started. \n",
    "\\\n",
    "\\\n",
    "Finally we will group the dataframe by `winner_name` and `streak_indicator_num` (in that order), aggregating using the `size` function, to see how larger each group (i.e. each streak) is.\n",
    "\\\n",
    "\\\n",
    "After sorting these values, we can pick the top 5 to get the top 5 streaks and the players associated with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.4: Apply your method to find the player with the 5 longest streaks, and the lenth of their streaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the rows by 'tourney_date'\n",
    "gs_df_men = gs_df_men.sort_values(by='tourney_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a streak indicator column in the men's dataframe\n",
    "gs_df_men['streak_indicator_bool'] = gs_df_men['winner_name'].eq(gs_df_men['winner_name'].shift())\n",
    "\n",
    "# Creating a streak indictor column that contains numbers that indicate different streaks\n",
    "gs_df_men['streak_indicator_num'] = (~gs_df_men['streak_indicator_bool']).cumsum()\n",
    "\n",
    "# Grouping the dataframe by 'winner_name' and 'streak_indicator_num' \n",
    "streaks_men = gs_df_men.groupby(['winner_name', 'streak_indicator_num']).size()\n",
    "\n",
    "# Sorting the streaks object to find 5 longest streaks \n",
    "highest_streaks = streaks_men.sort_values(ascending=False)\n",
    "\n",
    "# Getting the players who got the longest streaks\n",
    "players_with_highest_streak = list(highest_streaks.index.get_level_values('winner_name'))\n",
    "\n",
    "highest_streaks = list(highest_streaks.values)\n",
    "\n",
    "# Making a dictionary of the players with their streaks\n",
    "unique_highest_streaks = {\n",
    "    'player' : players_with_highest_streak,\n",
    "    'streak' : highest_streaks\n",
    "}\n",
    "\n",
    "# Making the dictionary into a dataframe\n",
    "unique_highest_streaks_df = pd.DataFrame(unique_highest_streaks)\n",
    "\n",
    "# Dropping rows that have the same pair of entries in the 'player' and 'streak' column \n",
    "unique_highest_streaks_df.drop_duplicates(subset=['player', 'streak'], inplace=True)\n",
    "\n",
    "# Getting the top 5 plpayers and streaks\n",
    "top_5_players = list(unique_highest_streaks_df['player'].head(5))\n",
    "top_5_streaks = list(unique_highest_streaks_df['streak'].head(5))\n",
    "\n",
    "# Printing the results\n",
    "print(f'Players with highest streaks are {top_5_players}, with streak(s) of {top_5_streaks}, respectively.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
