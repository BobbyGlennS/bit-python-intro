{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Python\n",
    "## Work sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is great.\n",
    "But it's a little bare bones.\n",
    "We need to import some libraries if we want to do data science.\n",
    "\n",
    "Libraries?\n",
    "Consider Python as your workbench.\n",
    "Libraries are like little lovingly crafted bags (independent shop vibes) with specific tools that allow you to create beautiful things on your workbench. \n",
    "Typically, you need to install libraries on your machine, but as we're using colab, they come pre-installed.\n",
    "We will cover installation of libraries in a separate session. \n",
    "R users will recognise the concept of libraries but might think of them as 'packages'.\n",
    "\n",
    "A very commonly used library in data science is [pandas](https://pandas.pydata.org/). \n",
    "It provides easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "We will use it a lot in this workshop.\n",
    "\n",
    "Other libraries often used are:\n",
    "\n",
    "- numpy: helps with doing maths on colletions of numbers (like a matrix).\n",
    "- sci-kitlearn & statsmodels fit machine learning and statistical models.\n",
    "- matplotlib, seaborn, and plotly are libraries used for data viz.\n",
    "\n",
    "For this workshop we will at least need pandas and a specific module that comes with plotly, named graph_objects. \n",
    "We import them in the following cell.\n",
    "\n",
    "Put your cursor in the cell and pressing `ctrl+enter` will execute the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: moving forward we will call a lot of the tools (called methods and functions) that come with pandas. \n",
    "Because we don't want to type 'pandas' everytime, we say 'as pd'. \n",
    "It means that we can now refer to pandas as pd, which saves a bit of typing. \n",
    "It is not essential.\n",
    "You can see we've done the same for plotly.graph_objects.\n",
    "\n",
    "As a next step, we will import the data we'll be playing around with today.\n",
    "Again, put your cursor in the cell, and press `ctrl+enter`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/BobbyGlennS/bit-python-intro/main/data/combined_matches.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dissect this piece of code a little bit:\n",
    "\n",
    "`df`    \n",
    "We don't just want to load the data, we will also need to tell python to store it somewhere. We are creating a variable named `df`. It will serve as a pointer to the data that we are about to load into the memory. This way python knows to keep hold of it, and let us bring it back up everytime we type `df`.\n",
    "\n",
    "\n",
    "`=`  \n",
    "We're telling python that this new variable should point to the result of the code that follows the equals sign (`=`).  \n",
    "\n",
    "`pd.read_csv`  \n",
    "Use the function read_csv from the pandas library (which we said we would refer to as pd).  \n",
    "\n",
    "`('https://....')`  \n",
    "Between the parentheses we provide an 'argument'. It's an instruction to the function. In this case the instruction is: 'go here to retrieve the file'.\n",
    "\n",
    "Great! \n",
    "If all went well we now have a dataset loaded.\n",
    "It's stored in Python's memory in an object called a pandas DataFrame, which we can retrieve by typing `df`.\n",
    "\n",
    "We can start playing.\n",
    "Let's first have a little look.\n",
    "Let's print the dataframe with a function named `print()`.\n",
    "\n",
    "Like with `read_csv()`, we write the function and between the parentheses we provide an argument that contains an instruction for the function to work with. In this case the instruction is to print of whatever we provide as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use also the *method* head() on a pandas DataFrame to get the first few rows, which looks slightly nicer.\n",
    "\n",
    "The technical distinction between methods and functions is something for another time. But what is useful to know is that methods are like little appendices that come with certain objects. A pandas DataFrame has a set of methods that you can use on it. For example to explore the dataframe, which is what we will be doing in the next few code cells.\n",
    "\n",
    "We call them slightly differently than functions: we write the object we want to use a method with, and then after the dot we write the name of the method.\n",
    "See below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also give methods specific instructions. That's what the parentheses are for! E.g. you can ask for a specific number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaving methods behind now for a second.\n",
    "\n",
    "We can also ask pandas to display specific columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# view tourney date, tourney name, and winner name columns\n",
    "df[['tourney_date', 'tourney_name', 'winner_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can combine different operations.\n",
    "We call this 'chaining'.\n",
    "This code is executed sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df[['tourney_date', 'tourney_name', 'winner_name']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some other operations that you may find useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#get column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# how many rows and columns?\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 0.1\n",
    "\n",
    "You've now seen a few ways to explore a dataframe.\n",
    "\n",
    "In the next cell, have a go yourself.\n",
    "\n",
    "- Can you create a subset of data by *sampling* 20 rows from a select set of *colums* of your choice? *Note: don't just select the top 5 rows, but sample some at random.*\n",
    "- Can you store this subset in a new pandas DataFrame?\n",
    "- Can you check the dimensions of this new dataframe?\n",
    "\n",
    "For this, you will need to use at least one new method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Data Wrangling\n",
    "\n",
    "Data wrangling is the process of transforming data from one form into another.\n",
    "\n",
    "Let's have a go.\n",
    "\n",
    "## Question: Who won the most Grand Slams between 2000 and 2019? Who won the most Australian Opens in the same period? \n",
    "\n",
    "Useful functions: \\\n",
    "\\\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html \\\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html \\\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html \\\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html \\\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html \\\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html\n",
    "\n",
    "Read about using plotly here: \\\n",
    "\\\n",
    "https://plotly.com/python-api-reference/generated/plotly.graph_objects.Bar.html\n",
    "\n",
    "First we might want to have a look at the date data for each match, and make sure that it is in the correct format.\n",
    "\n",
    "### Exercise 1.1: Have a look at the date of the matches and make sure that it is in the format YYY-MM-DD\n",
    "\n",
    "We can start by inspecting the 'tourney_date' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting a sample of 5 rows from the 'tourney_date' column\n",
    "df['tourney_date'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The date is in an unusual format that may be difficult to read. \n",
    "\n",
    "Let's change the format of this column using the 'to_datetime' function in pandas. See https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html for documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the date format\n",
    "df['tourney_date'] = pd.to_datetime(df['tourney_date'].astype(str), format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we first change the date to a string, so as to.......\n",
    "\n",
    "Let's check that it has worked as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the new 'tourney_date' column\n",
    "df['tourney_date'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good! \n",
    "\n",
    "Next we might want to only indlude relevant matches in the dataframe. This is known as filtering.\n",
    "\n",
    "### Exercise 1.2: Filter the dataframe to only include finals matches from Grand Slam Tournaments\n",
    "\n",
    "Using ChatGPT, StackOverflow, and your own brilliance, can you write some code that:\n",
    "- Keeps only rows where the value on the column `round` is `\"F\"`\n",
    "- Keeps only rows where the value on the column `tourney_level` is `\"G\"`\n",
    "\n",
    "First let's work out which matches are finals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['round'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good guess here would be 'F' for final. This can be checked by checking a specific row with 'F' in the 'tourney_level' column and seeing that the match detail are correct using google. \n",
    "\n",
    "Let's find the rows that correspond to grand slams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the 'tourney_level' column\n",
    "df['tourney_level'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is unclear which code corresponds to grand slams. Let's have a look at the tournament name and level for some rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['tourney_name', 'tourney_level']].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like 'G' is the level for grand slams. Let's check that all grand slams are included in this level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['tourney_level'] == 'G']['tourney_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good, except for the fact that there are multiple formats for some of the tournaments, which may cause issues when analysing the Australian Open tournaments. \n",
    "\n",
    "Let's rename some of them so that each grand slam only has one format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a dictionary of desired replacements\n",
    "replacements = {\n",
    "    'Us Open' : 'US Open',\n",
    "    'Australian Open-2' : 'Australian Open',\n",
    "    'Australian Chps.' : 'Australian Open',\n",
    "    'Australian Open 2' : 'Australian Open',\n",
    "    'Australian Championships' : 'Australian Open'\n",
    "}\n",
    "\n",
    "# Doing the replacements\n",
    "df['tourney_name'] = df['tourney_name'].replace(replacements)\n",
    "\n",
    "# Checking the replacements\n",
    "df[df['tourney_level'] == 'G']['tourney_name'].value_counts()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! This has worked and we are ready to make our filtered dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a dataframe that only includes grandslam finals\n",
    "gs_df = df[(df['tourney_level'] == 'G') & (df['round'] == 'F')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3: Find who won the most grand slam tournaments/Aus Open's between 2000 and 2019. Plot two bar charts showing this information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `groupby` function to do this. `groupby` groups data in a dataframe and applies some aggregate function to data within each group. For example, if we had data on \n",
    "\n",
    "See https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step is to filter the dataframe to only include matches that happened between 2000 and 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_df_time_res = gs_df[(gs_df['tourney_date'].dt.year >= 2000) & (gs_df['tourney_date'].dt.year < 2020)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to group this dataframe by `winner_name`. We will use the agregate funtion `size` as we wish to count the number of appearances of each player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_wins_grouped = gs_df_time_res.groupby('winner_name').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will order the series in descending order, and take the top 5 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_top_5 = gs_wins_grouped.sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you could do this in one line of code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_top_5 = gs_df[(gs_df['tourney_date'].dt.year >= 2000) & (gs_df['tourney_date'].dt.year < 2020)].groupby('winner_name').size().sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's extract the names and number of weeks for each player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_top_players = list(gs_top_5.index)\n",
    "gs_top_nums = gs_top_5.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure([go.Bar(x=gs_top_players, y=gs_top_nums)])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Grand Slam Wins by Top 5 Tennis Players',\n",
    "    xaxis_title='Players',\n",
    "    yaxis_title='Grand Slam Wins between 2000-2019',\n",
    "    template='plotly_dark'  \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.4: Make a bar chart showing which 5 players won the most Australian Opens between 2000 and 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution is very similar. Note that we have to add the condition that the tournament name is `Australian Open`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the grouped series\n",
    "most_aus = gs_df[(gs_df['tourney_date'].dt.year >= 2000) & (gs_df['tourney_date'].dt.year < 2020) & (gs_df['tourney_name'] == 'Australian Open')].groupby('winner_name').size().sort_values(ascending=False).head(5)\n",
    "\n",
    "# Getting the players and number of wins \n",
    "players_aus = list(most_aus.index)\n",
    "num_aus = most_aus.values\n",
    "\n",
    "# Plotting the bar chart\n",
    "fig = go.Figure([go.Bar(x=players_aus, y=num_aus)])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Australian Open Wins by Top 5 Tennis Players',\n",
    "    xaxis_title='Players',\n",
    "    yaxis_title='Australian Open Wins between 2000-2019',\n",
    "    template='plotly_dark'  \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serena Williams comes out on top again! It's interesting note that while Federer won more grandslams than Djokovic, he won less Australian Opens. It could be interesting to investigate what factors might cause this, for example court type. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Analysing Streaks\n",
    "\n",
    "Through this section, we will be analysing grand slam winning streaks from the men's dataframe.\n",
    "\n",
    "Usefull functions: \n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html \\\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.eq.html \\\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumsum.html \\\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.Index.get_level_values.html\n",
    "\n",
    "## Question 1: Which Male Players had the Longest Grand Slam Winning Streaks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Filter the grand slams dataframe to only include male players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataframe into male and female players\n",
    "gs_df_men = gs_df[gs_df['Tour'] == 'ATP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Shift the 'winner_name' column in the men's dataframe down by one using the shift function.\n",
    "\n",
    "Let's see what the shift function does to a column. First we check what the column looks like before applying the shift function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the 'winner_name' column before applying the shift function\n",
    "gs_df_men['winner_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shifting the 'winner_name' column down by 1\n",
    "gs_df_men['winner_name'].shift()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to shist the whole column down by one. Notice that the index remains the same. This is important for comparing the shifted row to the original. \n",
    "\n",
    "Now let's see what the eq function does. \n",
    "\n",
    "### Exercise 3.2: Use the `eq` function to compare the shifted 'winner_name' to the original. What is the result? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_df_men['winner_name'].eq(gs_df_men['winner_name'].shift())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a boolean array indicating when the two columns are the same (True), and when they are not (False).\n",
    "\n",
    "### Exercise 3.3: How can we use these functions to determine grand slam winning streaks for each player?\n",
    "\n",
    "Hint: you might find it helpful to use the `cumsum` function, with which you can sum values in a boolean array (https://pandas.pydata.org/docs/dev/reference/api/pandas.DataFrame.cumsum.html). \n",
    "\n",
    "Hint: also see https://joshdevlin.com/blog/calculate-streaks-in-pandas/#:~:text=The%20first%20step%20in%20calculating,us%20which%20are%20not%20equal for a blog post on how to find streaks in a dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution:\n",
    "\n",
    "We will solve this problem by first adding a `streak_indicator` column, that will be a boolean (as above) that indicates when the winning player is the same as in the shifted `winner_name` column. Then we will negate this column so that `False` indicates that the `winner_name` is the same as the previous `winner_name`. We can now apply the `cumsxum` function and create a new streak indicator column whose entries will be numbers that increment by 1 everytime a new streak is started. \n",
    "\\\n",
    "\\\n",
    "Finally we will group the dataframe by `winner_name` and `streak_indicator_num` (in that order), aggregating using the `size` function, to see how larger each group (i.e. each streak) is.\n",
    "\\\n",
    "\\\n",
    "After sorting these values, we can pick the top 5 to get the top 5 streaks and the players associated with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.4: Apply your method to find the player with the 5 longest streaks, and the lenth of their streaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the rows by 'tourney_date'\n",
    "gs_df_men = gs_df_men.sort_values(by='tourney_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a streak indicator column in the men's dataframe\n",
    "gs_df_men['streak_indicator_bool'] = gs_df_men['winner_name'].eq(gs_df_men['winner_name'].shift())\n",
    "\n",
    "# Creating a streak indictor column that contains numbers that indicate different streaks\n",
    "gs_df_men['streak_indicator_num'] = (~gs_df_men['streak_indicator_bool']).cumsum()\n",
    "\n",
    "# Grouping the dataframe by 'winner_name' and 'streak_indicator_num' \n",
    "streaks_men = gs_df_men.groupby(['winner_name', 'streak_indicator_num']).size()\n",
    "\n",
    "# Sorting the streaks object to find 5 longest streaks \n",
    "highest_streaks = streaks_men.sort_values(ascending=False)\n",
    "\n",
    "# Getting the players who got the longest streaks\n",
    "players_with_highest_streak = list(highest_streaks.index.get_level_values('winner_name'))\n",
    "\n",
    "highest_streaks = list(highest_streaks.values)\n",
    "\n",
    "# Making a dictionary of the players with their streaks\n",
    "unique_highest_streaks = {\n",
    "    'player' : players_with_highest_streak,\n",
    "    'streak' : highest_streaks\n",
    "}\n",
    "\n",
    "# Making the dictionary into a dataframe\n",
    "unique_highest_streaks_df = pd.DataFrame(unique_highest_streaks)\n",
    "\n",
    "# Dropping rows that have the same pair of entries in the 'player' and 'streak' column \n",
    "unique_highest_streaks_df.drop_duplicates(subset=['player', 'streak'], inplace=True)\n",
    "\n",
    "# Getting the top 5 plpayers and streaks\n",
    "top_5_players = list(unique_highest_streaks_df['player'].head(5))\n",
    "top_5_streaks = list(unique_highest_streaks_df['streak'].head(5))\n",
    "\n",
    "# Printing the results\n",
    "print(f'Players with highest streaks are {top_5_players}, with streak(s) of {top_5_streaks}, respectively.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
